# -*- coding: utf-8 -*-
"""Final Project -  Mask Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wtw7O1NkZU8xKWSK3_Xhvr4J1__wk61q

##Mask Detection

Â© 2022 Zaka AI, Inc. All Rights Reserved.

---
The goal of this project is to build a model that can detect whether a person is wearing a mask or not. You would be downloading the data from kaggle and then building you model while we guide you through the steps.

##Getting the Data

We start by getting the data. The data that we want is on kaggle and you can access it through this link: https://www.kaggle.com/omkargurav/face-mask-dataset What you will have to do, is to search for a way that allows you to download the dataset from kaggle directly into google colab (or your google drive). This process would save you the trouble from downloading the dataset locally and then uploading it to use it in colab.
"""

from google.colab import drive
from google.colab import files

drive.mount("/content/gdrive", force_remount=True)

files.upload()

!pip install -q kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d davids1992/speech-representation-and-data-exploration

"""Once the dataset is downloaded, it is going to be zipped, and in order to use it, you need to unzip it. Here you have the option of unzipping it in the environment or in your google drive."""

!unzip face-mask-dataset.zip

"""##Importing the Libraries

Now, it is time to import the libraries that we need.
"""

import os
import shutil
import random
import numpy as np
from matplotlib import pyplot as plt
import tensorflow as tf
import cv2

"""If we look at the data that we extracted, we can see that it is located in 2 folders: with_mask and without_mask. What we need to do now, is to create a hierarchy of folders that would help us specify the training, validation, and testing data. In order to do this you have to use the **os** and the **shutil** libraries that would help you creating folders, and moving images from a folder to another. In simple terms, the libraries helps you perform the same things that you do on your computer with your operating system, but in a programmatic way.

The initial dataset contains a lot of images belonging to the 2 classes, what we will do is randomly sample from this dataset so that we reduce the training and the tuning time.

We need to have in our final directories the following:
* Training: 500 images "with_mask", and 500 images "without_mask"
* Validation: 100 images "with_mask", and 100 images "without_mask"
* Testing: 50 images "with_mask", and 50 images "without_mask"
"""

#Test Your Zaka --- Create the Train, Validation and Testing Folder\
os.makedirs('wdata/train')
os.makedirs('wdata/test')
os.makedirs('wdata/valid')

#Test Your Zaka --- Create the classes folders inside of each folder you created above
os.makedirs('wdata/train/with_mask')
os.makedirs('wdata/train/without_mask')
os.makedirs('wdata/test/with_mask')
os.makedirs('wdata/test/without_mask')
os.makedirs('wdata/valid/with_mask')
os.makedirs('wdata/valid/without_mask')

#Test Your Zaka --- For each class, take the images, and select 500 samples for training and 100 for evaluation, and 50 for testing

raw_with_mask = 'data/with_mask/'
raw_without_mask = 'data/without_mask/'

for f in random.sample(os.listdir(raw_with_mask),500):
    shutil.move(raw_with_mask+f,'wdata/train/with_mask')

for f in random.sample(os.listdir(raw_without_mask),500):
    shutil.move(raw_without_mask+f,'wdata/train/without_mask')

for f in random.sample(os.listdir(raw_with_mask),100):
    shutil.move(raw_with_mask+f,'wdata/valid/with_mask')

for f in random.sample(os.listdir(raw_without_mask),100):
    shutil.move(raw_without_mask+f,'wdata/valid/without_mask')

for f in random.sample(os.listdir(raw_with_mask),50):
    shutil.move(raw_with_mask+f,'wdata/test/with_mask')

for f in random.sample(os.listdir(raw_without_mask),50):
    shutil.move(raw_without_mask+f,'wdata/test/without_mask')

"""##Inspecting the Dataset

Now we will see some characteristics of our dataset.

Define 3 variables: **training_path**, **validation_path**, and **testing_path** so that you can use them for the rest of the colab.
"""

#Test Your Zaka
training_path = '/content/wdata/train'
validation_path = '/content/wdata/valid'
testing_path = '/content/wdata/test'

"""To make sure that everythinh went correctly, write a code that counts the number of images that you have in your training directory for each of the 2 categories: with_mask and without_mask"""

#Test Your Zaka
count_with_mask = 0
count_without_mask=0

for path in os.scandir(training_path+'/with_mask'):
    if path.is_file():
        count_with_mask += 1

for path in os.scandir(training_path+'/without_mask'):
    if path.is_file():
        count_without_mask += 1

print('Number of Images in the Training Directory:\nWith Mask Category:', count_with_mask,'\nWithout Mask Category:', count_without_mask)

"""Do the same for the validation and the testing folders"""

#Test Your Zaka
count_with_mask = 0
count_without_mask=0

for path in os.scandir(validation_path+'/with_mask'):
    if path.is_file():
        count_with_mask += 1

for path in os.scandir(validation_path+'/without_mask'):
    if path.is_file():
        count_without_mask += 1

print('Number of Images in the Validation Directory:\nWith Mask Category:', count_with_mask,'\nWithout Mask Category:', count_without_mask)

#Test Your Zaka
count_with_mask = 0
count_without_mask=0

for path in os.scandir(testing_path+'/with_mask'):
    if path.is_file():
        count_with_mask += 1

for path in os.scandir(testing_path+'/without_mask'):
    if path.is_file():
        count_without_mask += 1

print('Number of Images in the Testing Directory:\nWith Mask Category:', count_with_mask,'\nWithout Mask Category:', count_without_mask)

"""Write a code that shows 5 random images for people with mask from your training set. """

#Test Your Zaka
from matplotlib import pyplot
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array

pyplot.figure(figsize=(15,10))

for i in range (5):
  pyplot.subplot(230 + 1 + i)
  img=random.choice([x for x in os.listdir(training_path+'/with_mask')])
  img_path= training_path+'/with_mask/'+img
  imo=load_img(img_path)
  imoa = img_to_array(imo)
  image = imoa.astype('uint32')
  pyplot.imshow(image)

pyplot.show()

"""Do the same for people without mask."""

pyplot.figure(figsize=(15,10))

for i in range (5):
  pyplot.subplot(230 + 1 + i)

  img=random.choice([x for x in os.listdir(training_path+'/without_mask')])
  img_path= training_path+'/without_mask/'+img
  imo=load_img(img_path)
  imoa = img_to_array(imo)
  image = imoa.astype('uint32')
  pyplot.imshow(image)

pyplot.show()

"""##Modeling

Define a model structure that can deal with the images that we have to classify them between the 2 classes.
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, AveragePooling2D, Flatten, Dropout

datagen = ImageDataGenerator( horizontal_flip=True, rotation_range=90, brightness_range=[0.3,1.5], zoom_range=[0.6, 1.4], rescale=1.0/255.0)

train_it = datagen.flow_from_directory(training_path, batch_size=32, target_size=(256,256), class_mode='binary')
eval_it = datagen.flow_from_directory(validation_path, batch_size=10, class_mode='binary')

model=Sequential()
model.add(Conv2D(64, (3,3), input_shape=(256,256,3),padding = 'same', activation='relu'))
model.add(AveragePooling2D())
model.add(Conv2D(96, (3,3),padding='same' ,activation='relu'))
model.add(AveragePooling2D())
model.add(Conv2D(32, (3,3) ,activation='relu'))
model.add(AveragePooling2D())
model.add(Flatten())
model.add(Dense(50, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

print(model.summary())

"""Train the model that you defined on the training data and evaluate it on the validation data. Feel free to tune the hyperparameters of your model until you reach a satisfying result on the validation set. </br>
**N.B:** Make sure to save the model training history in a variable to plot later the learning curve.
"""

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])

history=model.fit(train_it, epochs=30,steps_per_epoch=50, validation_data=eval_it)

from tensorflow.keras.models import model_from_json

model_json = model.to_json()
with open("model.json", "w") as json_file:
  json_file.write(model_json)

model.save_weights("model.h5")

from tensorflow.keras.models import save_model, load_model
filepath = '/content/gdrive/MyDrive/saved_model'
save_model(model, filepath)

"""Plot the accuracy curve and see if your model is overfit."""

acc_train = history.history['accuracy']
acc_val = history.history['val_accuracy']

epochs= range (1,31)
plt.plot(epochs, acc_train, 'r', label='Training accuracy')
plt.plot(epochs, acc_val, 'g', label='Validation accuracy')
plt.title('Training and Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

"""**Since the validation accuracy is respectively high, there is a big chance that the model overfits. This will be examinated better when evaluating a new (testing) dataset never seen before by the model**

Now you will evaluate the model that you built on the testing set that you kept aside since the beginning.

##Evaluate the model
"""

test_it = datagen.flow_from_directory(testing_path, batch_size=1, class_mode='binary')
results= model.predict(test_it)

scores = model.evaluate(test_it)

"""Now we want to visualize the confusion matrix in order to see how much our classifier is good in predicting different classes."""

y_pred = results.flatten()
y_pred = np.where(y_pred > 0.5, 1, 0)
y_pred.shape

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(test_it.labels, y_pred)
print(cm)

"""**What did you learn about your model from this confusion matrix?**

**The model performance is not as good as expected althought the training/validation accuracies are claiming a better performance**

##Error Analysis

Now we need to see for each of the images that we have in our testing set, what did the model predict. This helps us analyze the errors and try to think why the model predicted some things in the wrong way.
"""

for i in range(len(y_pred)):
  print('Actual Data:',test_it.labels[i],'Predicted Data:', y_pred[i])

"""**Try to derive some conclusions from the wrong predictions that your model has made. Meaning: why do you think these predictions were wrong?**

**Actually we have thought about 2 possible reasons behind the big number of wrong predictions:Even the model is overfit as we doubt before or the reason may be  that the model had a hard time correctly predicting images with masks with figures or different colors.**

**As for having hard predictions with colored images, we have tried to change the color of the images to gray-scaled. When fitting the system, it shows a worse performance with an accuracy of about 40%. As for the overfit, we have tried to do some improvements as shown below**

**Think of a way that you can use in order to improve the performance of your model, and implement it**

**We will re-create a new model using different improvement techniques in order to avoid the overfit of the system. This will include regularizations, dropout neurons, more data augmentation, shuffling training set, early stopping, etc.**
"""

from sklearn.utils import shuffle
#Data Augmentation:

train2_it = datagen.flow_from_directory(training_path, batch_size=10, target_size=(256,256), class_mode='binary', shuffle=True)
eval2_it = datagen.flow_from_directory(validation_path, batch_size=10, class_mode='binary')
test2_it = datagen.flow_from_directory(testing_path, batch_size=10, class_mode='binary')

#Adding Regulizers, dropouts, and 
from tensorflow.keras import regularizers

model2=Sequential()
model2.add(Conv2D(64, (3,3), input_shape=(256,256,3),padding = 'same', activation='relu'))
model2.add(AveragePooling2D())
model2.add(Dropout(0.15))
model2.add(Conv2D(96, (3,3),padding='same' ,activation='relu', kernel_regularizer=regularizers.l2(0.09)))
model2.add(AveragePooling2D())
model2.add(Dropout(0.3))
model2.add(Conv2D(32, (3,3) ,activation='relu', kernel_regularizer=regularizers.l2(0.05)))
model2.add(AveragePooling2D())
model2.add(Flatten())
model2.add(Dense(50, activation='relu', kernel_regularizer=regularizers.l2(0.1)))
model2.add(Dropout(0.1))
model2.add(Dense(1, activation='sigmoid'))

print(model2.summary())

#Implementing Early Stop
model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])
callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)

#Callbacks are used in the fitting function

history2=model2.fit(train2_it, epochs=30,steps_per_epoch=50, validation_data=eval2_it, callbacks=[callback])

acc_train2 = history2.history['accuracy']
acc_val2 = history2.history['val_accuracy']

epochs2= range (1,9)
plt.plot(epochs2, acc_train2, 'r', label='Training accuracy')
plt.plot(epochs2, acc_val2, 'g', label='Validation accuracy')
plt.title('Training and Validation Accuracy After Improvements')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

results2= model2.predict(test_it)
scores2 = model2.evaluate(test_it)

y_pred2 = results2.flatten()
y_pred2 = np.where(y_pred2 > 0.5, 1, 0)

cm2 = confusion_matrix(test_it.labels, y_pred2)
print(cm2)

"""**Unfortunately, the new model didn't show improvements althought the different techniques that we tried to implement**

**Your Friend took your code and ran it again, but obtained different accuracies on the different sets. How do you interpret this?**

**As has happened with us as teammates on this project. The colab chooses a random sample of the data, therefore fitting the model will probably give different results**
"""

